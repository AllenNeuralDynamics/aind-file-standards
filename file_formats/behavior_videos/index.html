<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Documentation for the Allen Institute for Neural Dynamics File Standards"><meta name=author content="Allen Institute for Neural Dynamics and Contributors"><link href=../../core/template/ rel=prev><link href=../ecephys/ rel=next><link rel=icon href=../../icon.ico><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.16"><title>Behavior Videos - AIND File Standards</title><link rel=stylesheet href=../../assets/stylesheets/main.7e37652d.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=black> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#standards-on-behavior-video-acquisition class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="AIND File Standards" class="md-header__button md-logo" aria-label="AIND File Standards" data-md-component=logo> <img src=../../logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AIND File Standards </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Behavior Videos </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=black aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=white aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/AllenNeuralDynamics/aind-file-standards title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> aind-file-standards </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Index </a> </li> <li class=md-tabs__item> <a href=../../core/contributing/ class=md-tabs__link> Core </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> File Formats </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="AIND File Standards" class="md-nav__button md-logo" aria-label="AIND File Standards" data-md-component=logo> <img src=../../logo.svg alt=logo> </a> AIND File Standards </label> <div class=md-nav__source> <a href=https://github.com/AllenNeuralDynamics/aind-file-standards title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill=currentColor d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> aind-file-standards </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Index </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Core </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Core </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../core/contributing/ class=md-nav__link> <span class=md-ellipsis> Contributing </span> </a> </li> <li class=md-nav__item> <a href=../../core/core-standards/ class=md-nav__link> <span class=md-ellipsis> Core Standards </span> </a> </li> <li class=md-nav__item> <a href=../../core/template/ class=md-nav__link> <span class=md-ellipsis> Template </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> File Formats </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> File Formats </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Behavior Videos </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Behavior Videos </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Page contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Page contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#version class=md-nav__link> <span class=md-ellipsis> Version </span> </a> </li> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#acquisitionrawprimary-data-format class=md-nav__link> <span class=md-ellipsis> Acquisition/Raw/Primary Data Format </span> </a> <nav class=md-nav aria-label="Acquisition/Raw/Primary Data Format"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#higher-bit-depth-recordings class=md-nav__link> <span class=md-ellipsis> Higher bit-depth recordings </span> </a> </li> <li class=md-nav__item> <a href=#application-notes class=md-nav__link> <span class=md-ellipsis> Application notes </span> </a> <nav class=md-nav aria-label="Application notes"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#acquisition-and-logging class=md-nav__link> <span class=md-ellipsis> Acquisition and Logging </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#relationship-to-aind-data-schema class=md-nav__link> <span class=md-ellipsis> Relationship to aind-data-schema </span> </a> </li> <li class=md-nav__item> <a href=#file-quality-assurances class=md-nav__link> <span class=md-ellipsis> File Quality Assurances </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../ecephys/ class=md-nav__link> <span class=md-ellipsis> Ecephys </span> </a> </li> <li class=md-nav__item> <a href=../fip/ class=md-nav__link> <span class=md-ellipsis> Fip </span> </a> </li> <li class=md-nav__item> <a href=../harp/ class=md-nav__link> <span class=md-ellipsis> Harp </span> </a> </li> <li class=md-nav__item> <a href=../nwb/ class=md-nav__link> <span class=md-ellipsis> Nwb </span> </a> </li> <li class=md-nav__item> <a href=../planar_ophys/ class=md-nav__link> <span class=md-ellipsis> Planar Ophys </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Page contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Page contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#version class=md-nav__link> <span class=md-ellipsis> Version </span> </a> </li> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#acquisitionrawprimary-data-format class=md-nav__link> <span class=md-ellipsis> Acquisition/Raw/Primary Data Format </span> </a> <nav class=md-nav aria-label="Acquisition/Raw/Primary Data Format"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#higher-bit-depth-recordings class=md-nav__link> <span class=md-ellipsis> Higher bit-depth recordings </span> </a> </li> <li class=md-nav__item> <a href=#application-notes class=md-nav__link> <span class=md-ellipsis> Application notes </span> </a> <nav class=md-nav aria-label="Application notes"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#acquisition-and-logging class=md-nav__link> <span class=md-ellipsis> Acquisition and Logging </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#relationship-to-aind-data-schema class=md-nav__link> <span class=md-ellipsis> Relationship to aind-data-schema </span> </a> </li> <li class=md-nav__item> <a href=#file-quality-assurances class=md-nav__link> <span class=md-ellipsis> File Quality Assurances </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=standards-on-behavior-video-acquisition>Standards on behavior video acquisition<a class=headerlink href=#standards-on-behavior-video-acquisition title="Permanent link">&para;</a></h1> <h2 id=version>Version<a class=headerlink href=#version title="Permanent link">&para;</a></h2> <p>0.2.0</p> <h2 id=introduction>Introduction<a class=headerlink href=#introduction title="Permanent link">&para;</a></h2> <p>This document describes the standards for acquiring video data from behavior experiments. The goal is to ensure that the data is correctly acquired, logged, and stored in a way that is compatible with AIND's data processing pipelines. We will draw the line on including metadata that relates to the video data itself and NOT to the hardware or software that acquired it. This is to ensure that the data format is self-contained, maintainable and potentially reusable by other applications.</p> <h2 id=acquisitionrawprimary-data-format>Acquisition/Raw/Primary Data Format<a class=headerlink href=#acquisitionrawprimary-data-format title="Permanent link">&para;</a></h2> <p>Following SciComp standards, video data from behavior experiments should be saved to the <code>behavior-videos</code> modality folder.</p> <p>Inside this folder, each camera should have its own directory, named <code>&lt;CameraName&gt;</code>. Inside each camera folder, there should be two files: <code>video.&lt;extension&gt;</code> and <code>metadata.csv</code>. The <code>video.&lt;extension&gt;</code> file should contain the video data, and the <code>metadata.csv</code> file should contain the metadata for the video.</p> <p><code>&lt;CameraName&gt;</code> is expected to match the name defined in the rig metadata file (<code>rig.json</code>)</p> <p>The folder structure will thus be:</p> <div class=highlight><pre><span></span><code>ðŸ“¦behavior-videos
â”£ ðŸ“‚BodyCamera
â”ƒ â”£ ðŸ“œmetadata.csv
â”ƒ â”— ðŸ“œvideo.mp4
â”— ðŸ“‚FaceCamera
â”ƒ â”£ ðŸ“œmetadata.csv
â”ƒ â”— ðŸ“œvideo.mp4
</code></pre></div> <p>If multiple streams from the same camera are acquired in the same session, an optional <code>datetime</code> suffix can be added to the container's name:</p> <div class=highlight><pre><span></span><code>ðŸ“¦behavior-videos
â”£ ðŸ“‚BodyCamera_2023-12-25T133015
â”ƒ â”£ ðŸ“œmetadata.cs
â”ƒ â”— ðŸ“œvideo.mp4
â”— ðŸ“‚BodyCamera_2023-12-25T145001
â”ƒ â”£ ðŸ“œmetadata.csv
â”ƒ â”— ðŸ“œvideo.mp4
</code></pre></div> <p>The metadata file is expected to contain the following columns:</p> <ul> <li> <p><code>ReferenceTime</code> - Time of the trigger given by hardware (e.g. Harp)</p> </li> <li> <p><code>CameraFrameNumber</code> â€“ Frame counter given by the camera API or manually added by user (e.g. using OS counter for webcams)</p> </li> <li> <p><code>CameraFrameTime</code> â€“ Frame acquisition time given by the camera API or manually added by the user (e.g. using OS scheduler for webcams).</p> </li> </ul> <p>As for the video, since the format will depend on the scientific question and software/hardware constrains, we will not enforce a specification. However, we strongly discourage the use of RAW, uncompressed data, and should the user not have a preference, we suggest the follow default:</p> <p>Use a separate online encoder and offline encoder for use during acquisition, and long-term storage, respectively</p> <p>For the online encoder:</p> <ul> <li>Acquire without any gamma correction</li> <li>Acquire with the mkv format so that files are not corrupted if acquisition is abnormally terminated, i.e. the video files should be named like <code>video.mkv</code></li> <li>Use <code>ffmpeg</code> with the following encoding codec string for online encoding (optimized for compression quality and speed):</li> </ul> <p>Note: this has been tested with monochrome videos with the raw pixel format <code>gray</code>. For color videos, the input arguments might need to be altered to match the color space of the input.</p> <ul> <li>output arguments: <code>-vf "scale=out_range=full,setparams=range=full:colorspace=bt709:color_primaries=bt709:color_trc=linear" -c:v h264_nvenc -pix_fmt yuv420p -color_range full -colorspace bt709 -color_trc linear -tune hq -preset p3 -rc vbr -cq 18 -b:v 0M -metadata author="Allen Institute for Neural Dynamics" -maxrate 700M -bufsize 350M -f matroska -write_crc32 0</code></li> <li>input_arguments: <code>-colorspace bt709 -color_primaries bt709 -color_range full -color_trc linear</code></li> </ul> <p>For offline re-encoding (optimized for quality and size):</p> <ul> <li>Use mp4 container for the final video, i.e. the video should be named like <code>video.mp4</code>.</li> <li>output arguments: <code>-vf "scale=out_color_matrix=bt709:out_range=full:sws_dither=none,format=yuv420p10le,colorspace=ispace=bt709:all=bt709:dither=none,scale=out_range=tv:sws_dither=none,format=yuv420p" -c:v libx264 -preset veryslow -crf 18 -pix_fmt yuv420p -metadata author="Allen Institute for Neural Dynamics" -movflags +faststart+write_colr</code></li> </ul> <h4 id=higher-bit-depth-recordings>Higher bit-depth recordings<a class=headerlink href=#higher-bit-depth-recordings title="Permanent link">&para;</a></h4> <p>Note: this hasn't been tested as thoroughly.</p> <p>For higher bit depth (more than eight) recordings, change the output arguments of the online encoding to be as follows: - output arguments: <code>-vf "format=yuv420p10le,scale=out_range=full,setparams=range=full:colorspace=bt709:color_primaries=bt709:color_trc=linear" -c:v hevc_nvenc -pix_fmt p010le -color_range full -colorspace bt709 -color_trc linear -tune hq -preset p4 -rc vbr -cq 12 -b:v 0M -metadata author="Allen Institute for Neural Dynamics" -maxrate 700M -bufsize 350M -f matroska -write_crc32 0</code></p> <p>The HEVC encoder must be used to support 10 bit depth, and the pixel format has been changed to <code>p010le</code> which is a yuv420-like 10 bit pixel format that is accepted by NVENC. We also recommend using <code>.mkv</code> videos at the rig, to reduce the risk of data loss.</p> <p>Note that this saves the pixel data at 10 bit depth, even if the camera is acquiring 12 or higher. NVENC does not support saving more than 10 bit pixel depths. However, saving 10 bit pixel depth before gamma encoding will result in more accurate gamma encoding for the second stage encoding.</p> <p>There is an intermediate pixel format, yuv420p10le, which is necessary at the time of writing for gray pixel format inputs due to incorrect chroma initialization for p010le. Depending on your pixel format, and recent changes to ffmpeg, this may not be necessary.</p> <p>For the video to retain 10 bit depth for long-term storage, the offline encoder will also need to be changed. For example, set the output arguments to: <div class=highlight><pre><span></span><code>-vf &quot;colorspace=ispace=bt709:all=bt709:dither=none,scale=out_range=tv:sws_dither=none,format=yuv420p10le&quot;
-c:v libx264 -preset veryslow -crf 18 -pix_fmt yuv420p10le
-metadata author=&quot;Allen Institute for Neural Dynamics&quot; -movflags +faststart+write_colr
</code></pre></div></p> <p>However, acquiring at 10 bits, gamma encoding, and saving 8 bit-depth videos for long-term storage is sufficient for many applications.</p> <h3 id=application-notes>Application notes<a class=headerlink href=#application-notes title="Permanent link">&para;</a></h3> <p>We currently support the following cameras: - <code>Blackfly S BFS-U3-16S2M</code> - <code>Blackfly S BFS-U3-04S2M</code></p> <p>Additional cameras could be supported but the user should provide the necessary information to integrate it with the current pipeline.</p> <div class="admonition caution"> <p class=admonition-title>Caution</p> <p>It is the user's responsibility to ensure that:</p> <ul> <li> <p>The camera is correctly calibrated and that the settings are appropriate for the experiment.</p> </li> <li> <p>Unless there is a reason not to, the default logging pattern should always follow the following logic: (Stop trigger if needed) -&gt; Start logging -&gt; Start Camera -&gt; Start Trigger -&gt; Acquire data -&gt; Stop Trigger -&gt; Stop Logging. This guarantees that all relevant events are recorded.</p> </li> <li> <p>Trigger generation only starts AFTER the camera hardware has been initialized. This is to ensure that the camera is ready to receive the first trigger signal.</p> </li> <li> <p>For each trigger of the trigger source (e.g. Harp Behavior board) a corresponding camera exposure should occur. One example where this can be violated is if the set exposure is greater than the trigger frequency.</p> </li> <li> <p>In absence of dropped frames (defined as skips in the FrameNumber &gt; 1) the metadata.csv file is expected to be aligned with the video file.</p> </li> <li> <p>(Optional) Start trigger and Stop trigger events should be available for QC.</p> </li> <li> <p>(Optional) The logs of all triggers (regardless of whether they are logged in the metadata.csv) should be saved for redundancy.</p> </li> </ul> </div> <h4 id=acquisition-and-logging>Acquisition and Logging<a class=headerlink href=#acquisition-and-logging title="Permanent link">&para;</a></h4> <p>Acquisition can be made using Bonsai. An operator that instantiates the camera can be found in <a href=https://allenneuraldynamics.github.io/Bonsai.AllenNeuralDynamics/api/AllenNeuralDynamics.Core.AindSpinnakerCapture.html>AllenNeuralDynamics.Core package</a>. This operator is a wrapper around the Spinnaker SDK and provides a simple interface to acquire video data. Since it forces the camera into the correct settings (e.g. Trigger mode, disabled gamma correction, etc...), it guarantees that camera metadata is static and thus easier to track.</p> <p>Logging can be implemented via the <a href=https://allenneuraldynamics.github.io/Bonsai.AllenNeuralDynamics/api/AllenNeuralDynamics.Core.FfmpegVideoWriter.html>FFMPEG operator</a>.</p> <p>While we suggest using the aforementioned recipes, the user is free to use any software that can acquire video data, provided it is validated and logged in the correct format.</p> <h3 id=relationship-to-aind-data-schema>Relationship to aind-data-schema<a class=headerlink href=#relationship-to-aind-data-schema title="Permanent link">&para;</a></h3> <p><code>&lt;CameraName&gt;</code> is expected to match the name defined in the rig metadata file (<code>rig.json</code>). Several fields in the metadata can be automatically extracted from this file format (e.g. start and stop of the stream, resolution of the video). However, the user should ensure that any data pertaining to the hardware configuration (e.g. camera model, exposure time, gain, camera position, etc...) is logged indepedently from this file format herein described.</p> <h3 id=file-quality-assurances>File Quality Assurances<a class=headerlink href=#file-quality-assurances title="Permanent link">&para;</a></h3> <p>The following features should be true if the data asset is to be considered valid:</p> <ul> <li> <p>The number of frames in the encoded video should match the number of recorded frames and the number of frames in the metadata.</p> </li> <li> <p>Check if dropped frames occurred. This should be done in two ways:</p> </li> <li> <p>The difference between adjacent FrameNumber is always 1;</p> </li> <li> <p>The difference between adjacent Seconds and adjacent FrameTime should be very close (I would suggest a threshold of 0.5ms for now);</p> </li> </ul> <div class="admonition note"> <p class=admonition-title>Note</p> <p>While dropped frames are not ideal, they do not necessarily invalidate the data. However, the user should be aware of the potential consequences and/or ways to correct the data asset.</p> </div> <ul> <li>If using a stable frame rate (this should be inferred from a rig configuration file), the average frame rate should match the theoretical frame rate;</li> </ul> <p>(optional) If the optional start and stop events are provided, the following temporal order should be asserted: <code>All(StartTrigger &lt; Frames &lt; StopTrigger&gt;)</code></p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="February 10, 2026 15:57:33 UTC">February 10, 2026</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> 2025, Allen Institute for Neural Dynamics </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["content.tabs.link", "announce.dismiss", "navigation.tabs", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.preview", "navigation.instant.progress", "navigation.path", "navigation.sections", "navigation.top", "navigation.tracking", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.50899def.min.js></script> </body> </html>